{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-17T08:36:04.615370Z",
     "start_time": "2024-07-17T08:35:59.295489Z"
    }
   },
   "source": [
    "pip install llamaindex\n",
    "pip install transformers\n",
    "pip install faiss-cpu  # vector database"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "articles = [\n",
    "    {\n",
    "        \"url\": \"https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/\",\n",
    "        \"content\": \"\"\"Enhancing RAG-Based Applications Accuracy by Constructing and Leveraging Knowledge Graphs...\n",
    "                      [full content here]\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://blog.langchain.dev/graph-based-metadata-filtering-for-improving-vector-search-in-rag-applications/\",\n",
    "        \"content\": \"\"\"Graph-Based Metadata Filtering for Improving Vector Search in RAG Applications...\n",
    "                      [full content here]\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "documents = [article['content'] for article in articles]\n"
   ],
   "id": "e052752457147c64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llamaindex import GPTIndexer, FAISSRetriever\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Initialize the tokenizer and model for embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_embeddings(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Prepare document embeddings\n",
    "document_embeddings = get_embeddings(documents)\n",
    "\n",
    "# Initialize FAISS retriever\n",
    "retriever = FAISSRetriever(vector_dim=document_embeddings.shape[1])\n",
    "retriever.add_embeddings(document_embeddings, documents)\n"
   ],
   "id": "1bd4f75d58a68967"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Initialize the T5 model and tokenizer\n",
    "model_name = \"t5-base\"\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate_answer(context, question):\n",
    "    input_text = \"context: {} question: {}\".format(context, question)\n",
    "    input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    outputs = t5_model.generate(input_ids, max_length=512, num_beams=5, early_stopping=True)\n",
    "    answer = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer\n"
   ],
   "id": "45159185258b8ada"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def rag_system(question):\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = retriever.retrieve(question, top_k=3)\n",
    "    context = \" \".join(retrieved_docs)\n",
    "\n",
    "    # Generate an answer based on retrieved context\n",
    "    answer = generate_answer(context, question)\n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "question = \"How does constructing and leveraging knowledge graphs enhance RAG-based applications accuracy?\"\n",
    "answer = rag_system(question)\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", answer)"
   ],
   "id": "7b7b9095a09cf31c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bb7696a897af1fe0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
